import time
import os
import mlflow
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler
from spam_trainer import SpamTrainer
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score

class MLOpsHandler(FileSystemEventHandler):
    def __init__(self):
        self.trainer = SpamTrainer()
        self.last_run = 0  # Pour √©viter les d√©clenchements multiples trop rapides

    def on_modified(self, event):
        # 1. On v√©rifie si c'est le dataset ou le code du mod√®le qui a chang√©
        is_data = event.src_path.endswith(os.path.basename(self.trainer.config.DATA_PATH))
        is_model_code = "spam_trainer.py" in event.src_path
        
        if (is_data or is_model_code) and (time.time() - self.last_run > 5):
            self.last_run = time.time()
            reason = "DONN√âES" if is_data else "CODE MOD√àLE"
            print(f"üîÑ Changement d√©tect√© ({reason}) : {event.src_path}")
            self.run_pipeline()

    def run_pipeline(self):
        print("üöÄ D√©marrage du pipeline MLflow...")
        try:
            # --- 1. Pr√©paration ---
            X, y = self.trainer.load_data()
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

            # --- 2. Preprocessing & Entra√Ænement ---
            # Important : Le vectorizer fait partie du mod√®le !
            X_train_vec, X_test_vec = self.trainer.preprocess(X_train, X_test)
            model = self.trainer.getmodel()
            model.fit(X_train_vec, y_train)

            # --- 3. √âvaluation ---
            y_pred = model.predict(X_test_vec)
            acc = accuracy_score(y_test, y_pred)

            # --- 4. Logging MLflow (Via ton Manager) ---
            # On ouvre un bloc mlflow ici pour logger les artefacts manuellement
            with mlflow.start_run(nested=True):
                # Enregistre le dataset utilis√© pour la tra√ßabilit√©
                mlflow.log_artifact(self.trainer.config.DATA_PATH, artifact_path="dataset_used")
                
                # Enregistre le vectorizer (obligatoire pour le backend)
                import joblib
                joblib.dump(self.trainer.vectorizer, "vectorizer.pkl")
                mlflow.log_artifact("vectorizer.pkl", artifact_path="model")

                # Utilisation de ton manager pour enregistrer le mod√®le proprement
                uri = self.trainer.mlflow.log_training_run(
                    model=model,
                    params={"max_iter": self.trainer.config.MAX_ITER, "source": "automation_v2"},
                    metrics={"accuracy": acc},
                    X_sample=X_test_vec
                )
            
            print(f"‚úÖ Pipeline r√©ussi. Accuracy: {acc:.4f} | URI: {uri}")
            # Dans automation.py, √† la fin de run_pipeline
            run_id = self.trainer.mlflow.get_latest_run_id("SpamClassifier")
            print(f"üÜî ID unique du run pour le backend : {run_id}")
            
        except Exception as e:
            print(f"‚ùå Erreur critique : {e}")

if __name__ == "__main__":
    handler = MLOpsHandler()
    # Lancement initial pour s'assurer que MLflow est √† jour
    handler.run_pipeline()
    
    observer = Observer()
    
    # Surveillance du dossier DATA
    data_dir = os.path.dirname(os.path.abspath(handler.trainer.config.DATA_PATH))
    observer.schedule(handler, path=data_dir, recursive=False)
    
    # Surveillance du dossier CODE (o√π se trouve spam_trainer.py)
    code_dir = os.path.dirname(os.path.abspath(__file__))
    observer.schedule(handler, path=code_dir, recursive=False)
    
    print(f"üì° Surveillance active sur :\n - Donn√©es: {data_dir}\n - Code: {code_dir}")
    observer.start()
    try:
        while True:
            time.sleep(1)
    except KeyboardInterrupt:
        observer.stop()
    observer.join()